from langchain_core.messages import AIMessage 

from .session_history import get_session_history
from .agent_base import AgentBase   
from utils.logger import LOG

class ConversationAgent(AgentBase):
    """
    Conversation Agent Class responsible for handling interactions with the user.
    """
    def __init__(self, session_id=None):
        super().__init__(
            name="conversation",
            prompt_file="prompts/conversation_prompt.txt",
            session_id=session_id
            )
        


# from langchain_ollama.chat_models import ChatOllama
# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
# from langchain_core.messages import HumanMessage
# from utils.logger import LOG
# from langchain_core.chat_history import (
#     BaseChatMessageHistory,
#     InMemoryChatMessageHistory,
# )
# from langchain_core.runnables.history import RunnableWithMessageHistory

# # Store History Chat
# store = {}

# def get_session_history(session_id: str) -> BaseChatMessageHistory:
#     """
#     Retrieve the chat history for the specified session ID. If the session ID does not exist, a new chat history instance will be created.

#     Parameters:
#         session_id (str): Unique identifier for the session

#     Outputs:
#         BaseChatMessageHistory: Chat history object for the corresponding session
#     """
#     if session_id not in store:
#         store[session_id] = InMemoryChatMessageHistory()
#     return store[session_id]

# class ConversationAgent:
#     """
#     Conversation Agent Class responsible for handling interactions with the user.
#     """
#     def __init__(self):
#         self.name = "Conversation Agent"  # Agent Name
        
#         # Read system prompt
#         with open("prompts/conversation_prompt.txt", "r", encoding="utf-8") as file:
#             self.system_prompt = file.read().strip()

#         # Create a chat prompt template, including a system prompt and message placeholders.
#         self.prompt = ChatPromptTemplate.from_messages([
#             ("system", self.system_prompt),  # System prompt
#             MessagesPlaceholder(variable_name="messages"),  # Message placeholder
#         ])

#         # Initialize the ChatOllama model and configure model parameters.
#         self.chatbot = self.prompt | ChatOllama(
#             model="llama3.1:8b-instruct-q8_0",  
#             max_tokens=8192,
#             temperature=0.8,  # Randomness of text generation
#         )

#         # Associate the chatbot with the message history
#         self.chatbot_with_history = RunnableWithMessageHistory(self.chatbot, get_session_history)

#         self.config = {"configurable": {"session_id": "abc123"}}

#     def chat(self, user_input):
#         """
#         Process user input and generate a response.

#         Parameters:
#             user_input (str): The message input by the user

#         Outputs:
#             str: The response generated by the agent
#         """
#         response = self.chatbot.invoke(
#             [HumanMessage(content=user_input)], 
#         )  
#         return response.content

#     def chat_with_history(self, user_input):
#         """
#         Process user input and generate a response with history, and log.
        
#         Parameters:
#             user_input (str): The message input by the user

#         Outputs:
#             str: The response generated by the agent
#         """
#         response = self.chatbot_with_history.invoke(
#             [HumanMessage(content=user_input)],
#             self.config,  
#         )
#         LOG.debug(response) 
#         return response.content
